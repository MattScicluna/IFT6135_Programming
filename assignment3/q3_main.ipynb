{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sR7sB_RtP-B"
      },
      "source": [
        "# Self-supervised learning \n",
        "In this question, we will implement Simsiam a simple and effective Self-supervised learning (SSL) method. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are running this code on Google Colab, uncomment the below cell and run it. Also, make sure you are saving the models in the right place that they can be used for resuming the training process or as a pretrained model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Mount your Google Drive\n",
        "# %matplotlib inline\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# install pytorch 1.9\n",
        "# !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMWAik4GtP-C"
      },
      "outputs": [],
      "source": [
        "# import requirements\n",
        "\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from q3_solution  import SimSiam\n",
        "\n",
        "from q3_misc import TwoCropsTransform, load_checkpoints, load_pretrained_checkpoints\n",
        "\n",
        "model_names = sorted(name for name in models.__dict__\n",
        "    if name.islower() and not name.startswith(\"__\")\n",
        "    and callable(models.__dict__[name]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJAAFb8ft-_M"
      },
      "source": [
        "## Running on GPU\n",
        "In Google Colab, you can run your code on device. This will be particularly important in CNN part of the assignment. To make sure the notebook is running on device, you can change the notebook settings with\n",
        "* (EN) `Edit > Notebook Settings`\n",
        "* (FR) `Modifier > ParamÃ¨tres du notebook`\n",
        "\n",
        "Be mindful not to use the device if your code does not need to run on GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_ZCqMv-uOb8"
      },
      "outputs": [],
      "source": [
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDqcxTx7tP-E"
      },
      "outputs": [],
      "source": [
        "# The parameters we will use\n",
        "\n",
        "# general\n",
        "seed = 2022\n",
        "num_workers = 2\n",
        "save_path = './'\n",
        "resume = None #None or a path to a pretrained model (e.g. *.pth.tar')\n",
        "start_epoch = 0\n",
        "epochs = 102 #Number of epoches (for this question 100 is enough, however for 1000 epoches, you will get closer results to the original paper)\n",
        "\n",
        "# data\n",
        "dir ='./data'\n",
        "batch_size = 1024\n",
        "\n",
        "# Siamese backbone model\n",
        "arch = \"resnet18\"\n",
        "fix_pred_lr = True # fix the learning rate of the predictor network\n",
        "\n",
        "#Simsiam params\n",
        "dim=2048\n",
        "pred_dim=512\n",
        "\n",
        "# ablation experiments\n",
        "stop_gradient=True # (True or False)\n",
        "MLP_mode=None # None|'no_pred_mlp'| 'fixed_random_init'\n",
        "\n",
        "# optimizer\n",
        "lr = 0.03\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "\n",
        "# knn params\n",
        "knn_k = 200 #k in kNN monitor\n",
        "knn_t = 0.1 #softmax temperature in kNN monitor; could be different with moco-t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCdjRGdDtP-E"
      },
      "outputs": [],
      "source": [
        "# set seeds\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KATAtPIVQnT"
      },
      "source": [
        "In the next section we will build the Simsiam architecture as shown in this figure (from https://arxiv.org/pdf/2011.10566.pdf). \n",
        "\n",
        "# Question 3.1\n",
        "The network includes an encoder `f` named `self.encoder` and a predictor h named `self.predictor`. \n",
        "\n",
        "* Complete the `SimSiam.forward` function  in `q3_solution.py`. This code will receive `x1` and `x2` as:\n",
        "\n",
        "```\n",
        "Input:\n",
        "      x1: first views of images\n",
        "      x2: second views of images\n",
        "```\n",
        "and compute the outputs of the network. which are as below:\n",
        "```\n",
        "z1, z2 = f(x1), f(x2) # projections, n-by-d\n",
        "p1, p2 = h(z1), h(z2) # predictions, n-by-d\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "Output:\n",
        "    p1, p2, z1, z2: predictors and targets of the network\n",
        "    See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "**Note**: Based on the `self.stop_gradient`, this function returns `z1` and `z2` with and without stop gradient. \n",
        "\n",
        "**Hint**: In Pytorch, to apply the stop-gradient operation to a variable let say `m`, You can detach it from the graph as `m.detach()`.\n",
        "\n",
        "![1-Figure1-1.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agmFDDxtbWN6"
      },
      "source": [
        "# Question 3.2\n",
        "\n",
        "* Complete the `CosineSimilarity.forward` function  in `q3_solution.py`. This code compute cosine similarity between two inputs  `x1` and `x2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaiO80R8hzVB"
      },
      "source": [
        "# Question 3.3\n",
        "\n",
        "* Complete the `SimSiam.loss` function  in `q3_solution.py`. This code compute the Simsiam loss:\n",
        "\n",
        "```\n",
        "L = D(p1, z2)/2 + D(p2, z1)/2 \n",
        "```\n",
        "where `D` is negative cosine similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc8iVdDI45_H"
      },
      "source": [
        "Now we can initiate the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOwipW2jtP-E",
        "outputId": "9c972d81-cbba-494b-bbc8-d3a0496f52e3"
      },
      "outputs": [],
      "source": [
        "# Simsiam Model\n",
        "print(\"=> creating model '{}'\".format(arch))\n",
        "model = SimSiam(models.__dict__[arch], dim, pred_dim, stop_gradient=True, MLP_mode=None)\n",
        "# print(model)\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKf2wTgsjoUH"
      },
      "source": [
        "Now we set the learning rate (LR) of the model. We fix the LR of the predictor as it showed better performance in the original paper. Then we define the optimizer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqEE-SZYtP-F"
      },
      "outputs": [],
      "source": [
        "# define and set learning rates\n",
        "init_lr = lr * batch_size / 256\n",
        "if fix_pred_lr:\n",
        "    optim_params = [{'params': model.encoder.parameters(), 'fix_lr': False},\n",
        "                    {'params': model.predictor.parameters(), 'fix_lr': True}]\n",
        "else:\n",
        "    optim_params = model.parameters()\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.SGD(optim_params, init_lr,\n",
        "                            momentum=momentum,\n",
        "                            weight_decay=weight_decay)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6D3j5xytP-G"
      },
      "outputs": [],
      "source": [
        "# We can resume from a previous checkpoint\n",
        "if resume:\n",
        "    model, optimizer, start_epoch = load_checkpoints(os.path.join(resume),model,optimizer,device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nYbHqGFkQwW"
      },
      "source": [
        "# Dataset and dataloader for Siamese network\n",
        "\n",
        "In this question, you will work on object classification task of CIFAR10 dataset. We use Pytorch CIFAR10 Dataset to download the dataset so you do not need to download it separately.  This dataset consist of high dimensional images $\\mathcal{X} \\subset \\mathbb{R}^{32\\times32\\times3}$ of 10 classes. We provide samplers to generate the different distributions that you will need for this question.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAD9GhtotP-G",
        "outputId": "281198f1-5a61-4caf-9715-df6b76b63f2c"
      },
      "outputs": [],
      "source": [
        "# define train and test augmentations for pretraining step \n",
        "train_transform = [\n",
        "    transforms.RandomResizedCrop(32, scale=(0.08, 1.)), \n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])]\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "# datasets and loaders\n",
        "train_data = datasets.CIFAR10(root=dir, train=True, transform=TwoCropsTransform(transforms.Compose(train_transform)), download=True)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=True)\n",
        "\n",
        "memory_data = datasets.CIFAR10(root=dir, train=True, transform=test_transform, download=True)\n",
        "memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "test_data = datasets.CIFAR10(root=dir, train=False, transform=test_transform, download=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqsUlRTZmIEm"
      },
      "source": [
        "In the next cell, we define a train and test function for one epoch of data. We  use k nearest-neighbor (KNN) `knn_predict` to monitor the performance of the model. (see https://arxiv.org/abs/1805.01978 for more details).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTJ0mhMRtP-G"
      },
      "outputs": [],
      "source": [
        "# train for one epoch \n",
        "def train(train_loader, model, optimizer, device):\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "\n",
        "        if device is not None:\n",
        "            images[0] = images[0].to(device, non_blocking=True)\n",
        "            images[1] = images[1].to(device, non_blocking=True)\n",
        "\n",
        "        # compute output and loss\n",
        "        p1, p2, z1, z2 = model(x1=images[0], x2=images[1])\n",
        "        loss = model.loss(p1,p2,z1,z2,similarity_function='CosineSimilarity')\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return losses\n",
        "\n",
        "# save checkpoints \n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
        "\n",
        "# test using a knn monitor\n",
        "def test(net, memory_data_loader, test_data_loader, device, knn_k, knn_t ):\n",
        "    net.eval()\n",
        "    classes = len(memory_data_loader.dataset.classes)\n",
        "    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
        "    with torch.no_grad():\n",
        "        # generate feature bank\n",
        "        for i, (data, target) in enumerate(memory_data_loader):\n",
        "            feature = net(data.to(device,non_blocking=True))\n",
        "            feature = F.normalize(feature, dim=1)\n",
        "            feature_bank.append(feature)\n",
        "        # [D, N]\n",
        "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
        "        # [N]\n",
        "        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n",
        "        # loop test data to predict the label by weighted knn search\n",
        "        for i, (data, target) in enumerate(test_data_loader):\n",
        "            data, target = data.to(device,non_blocking=True), target.to(device,non_blocking=True)\n",
        "            feature = net(data)\n",
        "            feature = F.normalize(feature, dim=1)\n",
        "            \n",
        "            pred_labels = knn_predict(feature, feature_bank, feature_labels, classes, knn_k, knn_t)\n",
        "\n",
        "            total_num += data.size(0)\n",
        "            total_top1 += (pred_labels[:, 0] == target).float().sum().item()\n",
        "\n",
        "    return total_top1 / total_num * 100\n",
        "\n",
        "# knn monitor as in InstDisc https://arxiv.org/abs/1805.01978\n",
        "# implementation follows http://github.com/zhirongw/lemniscate.pytorch and https://github.com/leftthomas/SimCLR\n",
        "def knn_predict(feature, feature_bank, feature_labels, classes, knn_k, knn_t):\n",
        "    # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
        "    sim_matrix = torch.mm(feature, feature_bank)\n",
        "    # [B, K]\n",
        "    sim_weight, sim_indices = sim_matrix.topk(k=knn_k, dim=-1)\n",
        "    # [B, K]\n",
        "    sim_labels = torch.gather(feature_labels.expand(feature.size(0), -1), dim=-1, index=sim_indices)\n",
        "    sim_weight = (sim_weight / knn_t).exp()\n",
        "\n",
        "    # counts for each class\n",
        "    one_hot_label = torch.zeros(feature.size(0) * knn_k, classes, device=sim_labels.device)\n",
        "    # [B*K, C]\n",
        "    one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
        "    # weighted score ---> [B, C]\n",
        "    pred_scores = torch.sum(one_hot_label.view(feature.size(0), -1, classes) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
        "\n",
        "    pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
        "    return pred_labels\n",
        "\n",
        "# adjust LR\n",
        "def adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
        "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
        "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
        "            param_group['lr'] = init_lr\n",
        "        else:\n",
        "            param_group['lr'] = cur_lr\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufGZzuXsnHHh"
      },
      "source": [
        "Now we are ready to pretraining the backbone network. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oUVDKkkp3hI"
      },
      "source": [
        "# Question 3.4\n",
        "* train a model for 200 epochs with and without gradient stopping and evaluated them. Plot training loss and Knn accuracy against training epochs. \n",
        "\n",
        "**Hint** To run the model without gradient-stopping you need to change `stop_gradient` to `False` and run the notebook. Also, you need to store the training loss and Knn accuracy for each step. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct7Aw5letP-H",
        "outputId": "32ea6cac-076e-4522-83d1-90b552e9f496"
      },
      "outputs": [],
      "source": [
        "# train loop \n",
        "for epoch in range(start_epoch, epochs):\n",
        "\n",
        "    adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
        "\n",
        "    # train for one epoch\n",
        "    losses = train(train_loader, model, optimizer, device)\n",
        "    print('Train Epoch: [{}/{}] Train Loss:{:.5f}'.format(epoch, epochs,np.array(losses).mean() ))\n",
        "\n",
        "\n",
        "    # test every 10 epochs\n",
        "    if epoch % 1==0:\n",
        "        acc1 = test(model.encoder, memory_loader, test_loader, device, knn_k, knn_t)\n",
        "        print('Test Epoch: [{}/{}] knn_Acc@1: {:.2f}%'.format(epoch, epochs, acc1))\n",
        "    \n",
        "    # save a checkpoint every 20 epochs\n",
        "    if epoch % 1 == 0:\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'arch': arch,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer' : optimizer.state_dict(),\n",
        "        }, is_best=False, filename=save_path + '/checkpoint_{:04d}.pth.tar'.format(epoch))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4CFUbdInek2"
      },
      "source": [
        "After the pretraining the network, we can evalute the model in a classification task. In the next cells we will load the backbone model and train an supervised linear classifier on frozen features. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXkS5KrxtP-H"
      },
      "outputs": [],
      "source": [
        "# linear eval\n",
        "print(\"=> creating model '{}'\".format(arch))\n",
        "model = models.__dict__[arch]()\n",
        "\n",
        "# freeze all layers but the last fc\n",
        "for name, param in model.named_parameters():\n",
        "    if name not in ['fc.weight', 'fc.bias']:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# init the fc layer\n",
        "model.fc.weight.data.normal_(mean=0.0, std=0.01)\n",
        "model.fc.bias.data.zero_()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lymz8YM2tP-I"
      },
      "outputs": [],
      "source": [
        "# load the pre-trained model from previous steps\n",
        "pretrained = './checkpoint_0001.pth.tar'\n",
        "if pretrained:\n",
        "    model, optimizer, start_epoch = load_pretrained_checkpoints(os.path.join(pretrained),model,optimizer,device)\n",
        "if device is not None:\n",
        "    model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rfom0XPatP-I"
      },
      "outputs": [],
      "source": [
        "# define loss function (criterion) and optimizer\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# optimize only the linear classifier\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "assert len(parameters) == 2  # fc.weight, fc.bias\n",
        "\n",
        "optimizer = torch.optim.SGD(parameters, init_lr,\n",
        "                            momentum=momentum,\n",
        "                            weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-Hu_WQhtP-I"
      },
      "outputs": [],
      "source": [
        "# define train and test augmentation for linear evaluation \n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    dir,\n",
        "    transform=train_transform,\n",
        "    download=True,\n",
        "    train=True\n",
        "    )\n",
        "val_dataset = datasets.CIFAR10(\n",
        "    dir,\n",
        "    transform=val_transform,\n",
        "    download=True,\n",
        "    train=False\n",
        "    )\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, #(train_sampler is None),\n",
        "    num_workers=num_workers, pin_memory=True) #, sampler=train_sampler)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=256, shuffle=False,\n",
        "    num_workers=num_workers, pin_memory=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CShKpghJtP-I"
      },
      "outputs": [],
      "source": [
        "# train for one epoch\n",
        "def train(train_loader, model, criterion, optimizer, device):\n",
        "\n",
        "    \"\"\"\n",
        "    Switch to eval mode:\n",
        "    Under the protocol of linear classification on frozen features/models,\n",
        "    it is not legitimate to change any part of the pre-trained model.\n",
        "    BatchNorm in train mode may revise running mean/std (even if it receives\n",
        "    no gradient), which are part of the model parameters too.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    losses=[]\n",
        "    top1=[]\n",
        "    top5=[]\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "\n",
        "        if device is not None:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(images)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.append(loss.item())\n",
        "        top1.append(acc1[0].cpu())\n",
        "        top5.append(acc5[0].cpu())\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return top1\n",
        "\n",
        "# validation\n",
        "def validate(val_loader, model, criterion, device):\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "    losses=[]\n",
        "    top1=[]\n",
        "    top5=[]\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            if device is not None:\n",
        "                images = images.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True)\n",
        "\n",
        "            # compute output\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            losses.append(loss.item())\n",
        "            top1.append(acc1[0].cpu())\n",
        "            top5.append(acc5[0].cpu())\n",
        "\n",
        "    return top1\n",
        "\n",
        "\n",
        "def sanity_check(state_dict, pretrained_weights):\n",
        "    \"\"\"\n",
        "    Linear classifier should not change any weights other than the linear layer.\n",
        "    This sanity check asserts nothing wrong happens (e.g., BN stats updated).\n",
        "    \"\"\"\n",
        "    print(\"=> loading '{}' for sanity check\".format(pretrained_weights))\n",
        "    checkpoint = torch.load(pretrained_weights, map_location=\"cpu\")\n",
        "    state_dict_pre = checkpoint['state_dict']\n",
        "\n",
        "    for k in list(state_dict.keys()):\n",
        "        # only ignore fc layer\n",
        "        if 'fc.weight' in k or 'fc.bias' in k:\n",
        "            continue\n",
        "\n",
        "        # name in pretrained model\n",
        "        k_pre = 'encoder.' + k[len('module.'):] \\\n",
        "            if k.startswith('module.') else 'encoder.' + k\n",
        "\n",
        "        assert ((state_dict[k].cpu() == state_dict_pre[k_pre]).all()), \\\n",
        "            '{} is changed in linear classifier training.'.format(k)\n",
        "\n",
        "    print(\"=> sanity check passed.\")\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i3pXGVHtP-J"
      },
      "outputs": [],
      "source": [
        "# train for the classififcation task\n",
        "for epoch in range(start_epoch, epochs):\n",
        "\n",
        "\n",
        "    adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
        "\n",
        "    # train for one epoch\n",
        "    acc1 = train(train_loader, model, criterion, optimizer,device)\n",
        "    print('Train Epoch: [{}/{}] Train acc1:{:.2f}%'.format(epoch, epochs,np.array(acc1).mean() ))\n",
        "\n",
        "\n",
        "    # evaluate on validation set\n",
        "    acc1 = validate(val_loader, model, criterion, device)\n",
        "    print('Val Epoch: [{}/{}] Val acc1:{:.2f}%'.format(epoch, epochs,np.array(acc1).mean() ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFkWanMytspa"
      },
      "source": [
        "# Question 3.5\n",
        "Investigate the effect of the predictor network by experimenting the below settings. Plot training loss and Knn accuracy against training epochs.\n",
        "\n",
        "* Remove the predictor by replacing it with an identity network.\n",
        "\n",
        "**Note** To do the theis sub-question, you need to change the `MLP_mode`.\n",
        "```\n",
        "MLP_mode=None # None|'no_pred_mlp'| 'fixed_random_init'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "q3_main.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3434d950bc5adb29e78a02b472706503847cf922d050bde9f1629b944539bae3"
    },
    "kernelspec": {
      "display_name": "simsiam1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
